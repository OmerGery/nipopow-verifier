\section{Implementation}

\subsection{Environment Set-Up}

\subsubsection{Existing Environments}

The first step towards implementation is to set up a comfortable and adjustable
environment. There are several environments one can use to build Solidity
applications, most popular of which are Truffle(ref), Remix(ref) and
Embark(ref). However, none of the aforementioned applications delivered the
experience we needed in the scope of our project, due to the lack of speed and
customization options. That led us to the creation of a custom environment for
importing, compiling, deploying and testing smart contracts.

We used Python(ref) to build our environment, since it is a powerful
and convenient programming language, and all of our dependencies had
Python implementations available. We developed our environment in
Linux(ref).

\subsubsection{Dependencies}

The components we used as building blocks are Web3(ref) which is a
powerful library for interacting with Ethereum, the Solidity v0.6.6
compiler(ref), and EthereumTester which is a set of tools for testing
Ethereum-based applications. For the purpose of our project, a private
blockchain running an Ethereum Virtual Machine (EVM) was deployed.
This is a common practice for Ethereum development since it greatly
facilitates testing procedures. Our environment supports multiple
EVMs, namely Geth(ref), Ganache(ref) and Py-EVM(ref).

\subsubsection{Ethereum Virtual Machines}

All aforementioned EVMs deliver an implementation that complies with
the specifications described at the Ethereum yellow paper(ref).
However, different implementations provide unique choices to the
developer, each of which helped us to progress effortlessly during
different stages of our work.

\paragraph {Py-EVM:} Py-EVM is an evolving EVM which is created mainly for
testing. The ease of access and use, the configuration freedom of its
underlying test chain and its effectiveness for small sized data helped our
first steps. However, as the input data size started to grow, the effectiveness
of the tool rapidly fell(ref).

\paragraph {Ganache:} Ganache is a popular EVM developed by the Truffle team.
Its speed and configuration freedom are its main advantages. However, its
extreme memory requirement made it impossible to use when the sizes of the
input became analogous to the Bitcoin blockchain size.

\paragraph {Geth:} Geth is another popular EVM which is created by the Ethereum
team. It supports heavy customization while its memory usage is very limited
compared to Ganache, even for extensive inputs. It is, however, slower than
Ganache.

The set of configurations we used for each EVM can be found in our
public repository(ref).

TODO: insert figure of Py-EVM vs Ganache vs Geth

\subsubsection{Gas Profiling}

Another useful utility we used is solidity-gas-profiler(ref), a profiling
utility by Yushih. This gave us great insights regarding the gas usage across
contract’s functions, and, consequently, helped us target the functionalities
that needed to be refined.

TODO: insert figure of gas profiling

\subsection{Model}

As mentioned above, we used a previous verifier implementation(ref) as a basis
for our implementation. Since we adopted common primitives, we used some of the
tools Giorgos et al.\ used for functionalities such as constructing blockchains
and proofs. For the purposes of our project, we needed to enhance the
functionality of the existing tools in some cases. We are thankful to the
writers for sharing their implementation. This greatly facilitated our work.

In this subsection, we describe the model that our work shares this the
previous implementation. This includes the following::

\begin{enumerate}
    \item
        Construct a blockchain
    \item
        Construct a proof for an event in the blockchain
    \item
        Verify the proof
\end{enumerate}


\subsubsection{Blockchain}

The tool that creates the blockchain was created by Andrew Miller, one of the
writers of Non-Interactive Proofs of Proof of Work(ref) paper.  The tool is
using the Bitcoin library(ref) to construct a blockchain similar to Bitcoin’s.
The interlink pointers are organized into a Merkle(ref) tree and the index is
determined by their level. For details regarding the level calculation, see
section(ref). The Merkle root of the interlink tree is a 32-bit value, and is
included in the block header as an additional value. The new size of the block
header is 112 bytes. In order to ensure security, it is important for the
interlink root to be included in the block header, as it is part of the proof.
Otherwise, attackers could attack the proofs by reordering or including stray
blocks. Miners can easily verify that the Merkle root is correct.

TODO: figure of the blockchain

\subsubsection{Superblock Levels}

We assume that the difficulty target of mined blocks is constant. As discussed
in section(ref), this is not the actual setting of the Bitcoin blockchain. The
definition of superblocks is changed to a simpler definition and the level is
determined by the number of leading zeros of the block header hash. Although
this change does not take into account the difficulty target, the scoring of
proofs does not generate security holes in the protocol.

\subsubsection{Proof}

The tool that creates proofs was also created by Andrew Miller. The
prover receives the following inputs:

\begin{itemize}
    \item
        A blockchain with interlinks
    \item
        The security parameter k
    \item
        The security parameter m
\end{itemize}

Security parameters k, m are part of the NIPoPoW model and are
explained in section(ref).

The prover’s output is a Proof of Proof of Work that satisfies the
above security parameters. The prover needed to be enhanced in order
to create special test cases (section(ref)) and enable our optimized
architecture (section(ref)).

TODO: figure of proof

\subsubsection{Verifier}

The goal of the verifier is to accept valid proofs and discard invalid
proofs. A proof is submitted in combination with a predicate. The
proof is considered valid if it is constructively correct and the
predicate is true for the chain described by the proof. The predicate
can represent the existence of an event in the source blockchain, such
as the occurrence of a transaction. In our case, the predicate
indicates the existence of a block in the proof.

The verifier functions in two phases: (a) submit phase and (b) contest
phase. Each phase has different inputs and functionalities, and is
performed by different entities.

\paragraph{Submit phase} During the submit phase, an entity submits a proof and
an event. During this phase, we assume that at least one honest full node is
aware of the submission. This is also a part of the model of NIPoPoWs, and is a
logical assumption as explained in the paper. In order to claim the occurrence
of an event, one must provide a proof and a predicate regarding the underlying
event. If a certain number of rounds passes without successful contests,
the proof is considered valid and the predicate is considered true. The passing
of rounds is indicated by the mining of new blocks atop of the block containing
the submission.

\paragraph{Contest phase} If the submitted proof is invalid (i.e.\ the
predicate is not true for the honest chain), a contesting, better proof is
submitted, invalidating the original proof and predicate. The contesting proof
is considered better only if it encapsulates more Proof of Work than the
existing proof, as described in the NIPoPoWs paper. In order to contest, one
must provide a contest proof and the predicate that is claimed to be true by
the originally submitted proof. If the contesting proof has better score, then
the predicate is evaluated against the contesting proof.\\

The expected functionality of a NIPoPoW verifier is the following:
\begin{itemize}

    \item
        if an \textit{honest} party submits a proof and no contest occurs, then
        $predicate$ becomes $true$.

    \item
        If an \textit{honest} party submits a proof and it is contested by an
        \textit{adversary}, then the contest should be unsuccessful and the
        $predicate$ should remain $true$.

    \item
        If an \textit{adversary} submits a proof, then an \textit{honest} party
        should make a contest. The contest should invalidate the original
        submission and the $predicate$ should become $false$.

    \item
        The scenario in which an \textit{adversary} submits a proof and it is not
        followed by an \textit{honest} contest should not take place due to the
        assumption that at least one honest party observes the traffic of the
        contract.

\end{itemize}

\subsection{Previous Implementation}

In this subsection we present previous work. We prepare the reader by focusing
at specific aspects in which our solution differs. We will later show these
differences and we will analyse on how they impact the results of our
application.

In the process of building our Bitcoin Client, a suit of thorough unit tests
were written to assert the correction of our results which we also used at the
previous work. We discovered some erroneous functionalities that we appose in
subsection \ref{sssc:Security Analysis}

\subsubsection{Overview} As mentioned in the NIPoPoWs(ref Algorithm 7) paper,
in order to construct a verifier, a Directed Acyclic Graph (DAG) needs to be
maintained in memory. This structure is stored in the form of a hashmap(ref),
and is used to host blocks of all different proofs. This process aims to
prevent adversarial proofs which are structurally valid but blocks are
intentionally skipped. Such a scenario is displayed in
Figure~\ref{figure:DAG_usage}. The DAG is then used to construct ancestors
structure. Ancestors are created performing a simple graph search in DAG. By
iterating ancestors, we can securely determine the value of the predicate.

\input{figures/DAG_usage.tex}

This logic is intuitive and efficient to implement in most traditional
programming languages (C++, JAVA, Python, JavaScript, etc). However, such an
algorithm cannot be efficiently implemented in Solidity as is. This is not due
to the lack of features, such as the existence of hashmaps, but because
Solidity treats storage differently than most programming languages. As
mentioned above(ref) in smart contracts the caller needs to pay in gas for the
execution of operations such as accessing and storing data. Reading from and
writing to persistent memory are very expensive operations in Solidity, as
stated in the Ethereum yellow paper(ref). A summary of gas costs for storage
and memory access if is displayed in Table~\ref{table:ethereum_gas_list}. This
fact was observed by Giorgos et al.\ and was recognized as the bottleneck of
the application.

\input{tables/yellow_paper_gas.tex}

\subsubsection{Phases}

We describe each phase of the previous implementation in
Algorithms~\ref{algo:submit_old} and~\ref{algo:contest_old}. We highlight
structures that access persistent memory. Note that deleting from persistent
memory is also considered a storage operation

\input{algorithms/old_contract.tex}

\subsubsection{Gas analysis}

Here, we layout experiments that show the gas usage of the previous
implementation. In these experiments, we used a small proofs\footnote{For
sizes of proofs for realistic blockchain sizes, refer to Section(ref)}. These
sizes are unrealistic for a real blockchain, but are helpful to demonstrate the
gas of the functions of the contract for each phase. The gas expend for submit
and contest for proof of 20 blocks is shown in Table~\ref{table:old_gas_usage}.
We observe that even for small proofs, the gas cost is high - 4 million gas
units, given that the block gas limit of Ethereum is currently at
9.908.813(ref) gas units. This is mainly due to the extensive storage usage.

\input{tables/old_gas_usage.tex}

\subsubsection{Security Analysis}

\paragraph{Pre-mining} We observed that the smart contract is vulnerable to
pre-mining(ref). By definition, a valid NIPoPoW is structurally correct if two
properties are satisfied:

\begin{enumerate}[(a)]

\item The interlink structure of all blocks is correct. This is to prevent
    adversaries from injecting blocks that do not exist in the original
    blockchain.

\item The first block of proof is $genesis$. This is to prevent adversaries
    from create coins before blockchain are initiated at the public network.

\end{enumerate}

The second property is not verified in the previous work, exposing the verifier
to pre-mining attacks. We can easily mitigate this vulnerability by
initializing the smart contract with the $genesis$ block of the blockchain we
will use to create proofs, and add an assertion in submit and contest phase
that proofs need to satisfy property (b). The needed changes are shown in
Algorithms~\ref{algo:avoid_premining_ctor}
and~\ref{algo:avoid_premining_submit}.

\input{algorithms/avoid_premining.tex}

\bigbreak
\paragraph{Score Calculation}

During our tests, we observed that the calculation of proofs score was
incorrect. The score of each level is needed to determine which proof
represents the chain with the most Proof of Work. Between two proofs, we only
need to calculate the score starting from their $lca$ until the tip of each
proof. Different levels are needed because the $lca$ between two proofs is only
known when the contesting proof is submitted. The security parameter $m$ needs
to be satisfied for every sub-proof $proof[:lca]$. We ensure that this is true
by creating proofs of multiple levels, so that security parameter $m$ will
apply, disregarding the position of the $lca$,

TODO: Figure for the need of multiple levels

Each block has a level, calculated as describe in Section(ref)
\[ level = getLevel(block) \]

Consequently, each level of the proof consists of a number of blocks
$n_{level}$. This number is the sum of blocks of level $\geq$ $level$, i.e.\
block of level $l$ are also blocks of levels $l-1$, $l-2$, etc. The
score of each level is computed as:

\[score_{level} = 2^{level} \times n_{level}\]

We observed that function $getLevel(block)$ of the contract was returning
$block.level-1$ instead of $block.level$ resulting to incorrect score
computation. This can prevent an honest party from successfully contesting an
adversarial proof, making the contract insecure. The function was refined to
return the correct value.

\subsection{Storage Elimination}

As mentioned above, the bottleneck we had to eliminate was the extensive usage
of storage. We created a new architecture that allow us to discard all
expensive store operations and utilize memory instead. This led to massive
decrease of gas consumption. In this section, we present the difference in gas
usage between storage and memory utilization, and how a NIPoPoW verifier can be
implemented in Solidity without persisting proofs.

\subsubsection{Storage vs Memory}

We will first demonstrate the difference in gas usage between storage and
memory for a smart contract in Solidity. Suppose we have the following simple
contract:

\lstinputlisting[style=customc, captionpos=b, label={listing:storage_memory},
caption={Solidity test for storage and memory}]{code/StorageVsMemory.sol}

Function \texttt{withStorage()} populates an array saved in storage and
function \texttt{withMemory()} populates an array saved in memory. We
initialize the sizes of the arrays by passing the variable \texttt{size} to the
contract constructor. We run this piece of code for \texttt{size} from 1 to
100. The results are displayed at Figure~\ref{figure:memory_vs_storage}. For
\texttt{size} = 100, the gas expended is 53,574 using memory and 2,569,848
using storage which is almost 50 times more expensive. This code was compiled
with Solidity version 0.6.6 with optimizations enabled\footnote{This version of
Solidity compiler, which was the latest at the time this paper was published,
did not optimize-out any of the variables.}. The EVM we used  was Ganache at
the latest Constantinople(ref) fork. It is obvious that if there is the option
to use memory instead of storage in the design of smart contracts, it greatly
benefits the users.

\input{figures/memory_vs_storage.tex}

\subsubsection{Making use of calldata}

In previous work we needed to store submitted proofs in order to proceed to
contest. In this subsection we show an approach to securely verify proofs
without utilizing the persistent memory of the smart contract.

The rationale is to demand from the caller to provide two proofs to the
contract during contest phase: (a) $\pi_{exist}$, which is a copy of the
originally submitted proof $\pi_{orig}$, and (b) $\pi_{cont}$, which is the
contesting proof. Proof $\pi_{orig}$ can be retrieved by observing contract's
\textit{calldata}. We prevent an adversary from malforming $\pi_{exist}$ by
storing the hash of $\pi_{orig}$ to contract's state during submit phase and
then verifying that $\pi_{exist}$ has the same hash. The operation of hashing
the proof and storing the digest is cheap\footnote{By setting $k=6$, $m$ = 13,
a proof for the entire Bitcoin blockchain consists of less than 300
superblocks. The hashing of such a proof costs approximately 300,000 gas
units.} as shown in figure~\ref{figure:hash_proof_gas}. We calculate the digest
of the proof by:

\[\texttt{digest = sha256(abi.encodePacked(proof))}\] The size of the digest of
a hash is 32 bytes. To persist such a small value in contract's memory only
adds a constant, negligible cost overhead to our implementation.

\input{figures/hash_proof_gas.tex}

\subsubsection{Removing DAG and ancestors}

As shown in table~\ref{table:old_gas_usage}, the most demanding operation is
the creation and population of DAG and ancestors. In this subsection we show
how these two structures can be discarded from the verifier.

In this subsection we will use the notation displayed in
table~\ref{table:notation}.

\input{tables/notation.tex}

\paragraph{Using subset} Our first realization was that instead of storing the
DAG of $\pi_{exist}$, $\pi_{cont}$, we can require

\[ \pi_{exist}\{:lca_{e}\} \subseteq \pi_{cont}\{:lca_{c}\} \]
where $lca_{e}$ and $lca_{c}$ are the indices of the $lca$ block in
$\pi_{exist}$, and $\pi_{cont}$, respectively. This way we avoid
the demanding need of composing auxiliary structures DAG and ancestors
on-chain. The implementation of \texttt{subset} is displayed in
listing~\ref{listing:subset}. The complexity of the function is
\[ \mathcal{O}(\mid\pi_{exist}[:lca_{e}]\mid + \mid\pi_{cont}[:lca_{c}]\mid) \]

\lstinputlisting[style=customc, captionpos=b, label={listing:subset},
caption={Implementation of subset}]{code/Subset.sol}

\input{figures/subset_usage.tex}

The gas consumption difference between $subset$ and $DAG + ancestors$ is
displayed at figure~\ref{figure:DAG_vs_subset}. $Subset$ solution is
approximately 2.7 times more efficient.

\input{figures/DAG_vs_subset.tex}

\paragraph{Subset complexity and limitations} Requiring $\pi_{exist}$ to be a subset of
$\pi_{cont}$ greatly reduces gas, but the complexity of the $subset$ algorithm
is high since both proofs have to be iterated from genesis to their respective
$lca$ index. Generally, we expect for an adversary to provide a proof of a
chain that is a fork of the honest chain at some point relatively close to the
tip. This is due to the fact that the ability of an adversary to sustain a fork
chain is exponentially weakened as the honest chain progresses.  This means
that the length of $\pi$, $\mid\pi\mid$ will be considerably close to
$\mid\pi[:lca]\mid$, and the complexity of \texttt{subset()} is effectively
$\mathcal{O}(2\mid\pi\mid)$.

In realistic cases, where the $lca$ lies around index 250, the gas cost of
\texttt{subset()} is approximately 20,000,000 gas units, which makes it
inapplicable for real blockchains since it exceeds the block gas limit of Ethereum
blockchain by far.
\paragraph{Position of block of interest} By analyzing the benefits of
$subset$, we concluded that there is a more efficient way to treat storage
elimination. In general, the concept of $subset$ facilitated the case in which
the block of interest belongs in the sub-proof $\pi_{exist}[:lca_{e}]$. But in
this case, both $\pi_{exist}$ and $\pi_{cont}$ contain the block of interest at
some index, as can be seen in figure~\ref{figure:after_subset}. Consequently,
$\pi_{cont}$ cannot contradict the existence of the block of interest and the
predicate is evaluated $true$ for both proofs. This means that if (a)
$\pi_{exist}$ is structurally correct and (b) the block of interest is in
$\pi_{exist}[:lca_{e}]$, then we can safely conclude that contesting with
$\pi_{cont}$ is redundant. Therefore, $E_{c}$ can simply send
$\pi_{cont}$[lca:] to the verifier. The truncation of $\pi_{cont}$ to
$\pi_{cont}[lca_{c}:]$ can be easily addressed from $E_{c}$, since
$\pi_{exist}$ is accessible from the contract's calldata and both proofs can be
iterated off-chain.

We will refer to the truncated contesting proof as $\pi_{cont}^{tr}$ and to
$lca_{e}$ simply as $lca$. For the aforementioned, the following is true:
\begin{enumerate}[(a)]
    \item  $\pi_{exist}[0]$ = $Genesis$
    \item  $\pi_{exist}[lca]$ = $\pi_{cont}^{tr}[0]$
\end{enumerate}

\newcommand*{\exist}{$\pi_{exist}$}
\newcommand*{\cont}{$\pi_{cont}^{tr}$}

\paragraph{Disjoint proofs} A requirement we need to satisfy is that
$\pi_{exist}[lca:]$ and $\pi_{cont}^{tr}$ are disjoint. The implementation of
this operation is shown in listing~\ref{listing:disjoint}. The complexity of
\texttt{disjoint()} is $\mathcal{O}(\mid\pi_{exist}[lca_{e}:]\mid \times
\mid\pi_{cont}lca_{c}^{tr}\mid)$.

\lstinputlisting[style=customc, captionpos=b, label={listing:disjoint},
caption={Implementation for disjoint proofs}]{code/Disjoint.sol}

% \subsection{Targeting vulnerabilities and costly functionalities}
%
% \subsection{Fixing vulnerabilities and restricting gas usage}
%
% \begin{itemize}
%
%     \item
%         Even the check of subset can be skipped. The contesting proof cannot
%         benefit from pre-lca malformed proof. If Pa is valid, then we just
%         need to check Pb[lca:]
%
%     \item
%         This is not vulnerable to DOS attacks
%
%     \item
%         Observe the network and contest with the appropriate proof if
%         submitted is not correct.
%
% \end{itemize}

\pagebreak
